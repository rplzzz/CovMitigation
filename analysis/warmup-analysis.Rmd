---
title: "R Notebook"
output: html_notebook
---

```{r setup}
library(doParallel)
library(dplyr)
library(here)
library(metrosamp)
library(ggplot2)
library(tidyr)
library(CovMitigation)

registerDoParallel(8)

set.seed(867-5309)
```

```{r loaddata}
datadir <- here('analysis', 'mcmc-rslts', 'warmup-1')
warmup_files <- list.files(path=datadir, pattern='mcmc-warmup.*\\.rds', full.names=TRUE)

warmups <- lapply(warmup_files, readRDS)

cwarmups <- metrosamp2coda(warmups, 2500)
```

## Expectation value and credible intervals
```{r basicanalysis}
cat('\nAcceptance ratio by chain:\n')
sapply(warmups, accrate)
cat('\nOverall acceptance rate:\n')
accrate(warmups)
cat('\nEffective samples:\n')
print(neff(warmups))
cat('Expectation values:\n')
print(signif(EV(warmups), 2))
cat('\nCredible intervals:\n')
print(signif(CI(warmups), 2))
cat('\nRhat statistic:\n')
coda::gelman.diag(cwarmups)
```


## Improving the sampling

The acceptance rate is really high, which is contributing to both poor sampling
efficiency and poor mixing.  Ideally we would want to make the sampling steps
large enough that the chains might be able to mix, but that may give us an 
acceptance rate that is too low, but it's worth a try.

```{r cor}
allsamps <- getsamples(warmups, thinto=1600)
covm <- cov(allsamps)
signif(covm,3)
```

Let's try sampling with this covariance matrix and see how we do.
```{r samptest}

lpost <- gen_post()

p0 <- warmups[[1]]$plast
ms1 <- metrosamp(lpost, p0, 1000, 1, covm)
ms1$accept
neff(ms1$samples)
```

We're only accepting one out of every thousand proposals, which is a bit low, but
this is a very large proposal distribution.  We can shrink the distribution down
quite a bit and potentially still get some good mixing.  The covariance matrix
is effectiely the square of the scale, so dividing by 10 reduces the scale by 3.

```{r samptest2}
ms2 <- metrosamp(lpost, ms1, 1000, 1, covm/10)
ms2$accept
neff(ms2)
```

The acceptance rate is still pretty low, as is the sampling efficiency, but we may
just have to live with it, if we want to have any kind of decent mixing.  Here is
the range of values we are trying to cover.  

```{r densplots}
pltdata <- pivot_longer(as.data.frame(allsamps), everything(), names_to = 'parameter')
ggplot(data=pltdata, aes(x=value)) + geom_density(fill='LightGrey', alpha=0.5) + facet_wrap(~parameter, scales='free') +
  theme_bw()

```

```{r samptest3}
ms3 <- metrosamp(lpost, ms1, 1000, 1, covm/5)
ms3$accept
neff(ms3)
cat('Proposal distribution scale:\n')
sqrt(diag(covm/5))
```

This is pretty good, but the size of the T0_lo and T0_ulo proposal steps look 
rather large.  The outlier values for these two parameters don't have great pdf
values, so even with a smaller step they should be able to find their way into
more reasonable ranges.

```{r newscl}
scl <- sqrt(diag(covm/5))
scl[3:4] <- 10
sclmat <- cor2cov(cor(allsamps), scl)
ms4 <- metrosamp(lpost, ms3, 1000, 1, sclmat)
ms4$accept
neff(ms4)
cat('Proposal distribution scale:\n')
sqrt(diag(sclmat))
```

